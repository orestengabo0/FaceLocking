# Configuration file for the Integrated Face Tracking System\n# Copy this to config.py and customize for your setup\n\nimport logging\nfrom pathlib import Path\n\n# ============================================\n# Logging Configuration\n# ============================================\nLOG_LEVEL = logging.INFO\n# Options: logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR\n\nLOG_FORMAT = \"[%(levelname)s] %(name)s: %(message)s\"\n\n# ============================================\n# Camera Configuration\n# ============================================\nCAMERA_INDEX = 2\n# Try 0, 1, 2, etc. if not sure which camera is your USB device\n\nCAMERA_WIDTH = 1280\nCAMERA_HEIGHT = 720\nCAMERA_FPS = 30\n\n# ============================================\n# Face Detection Configuration\n# ============================================\nHAAR_CASCADE_PATH = None\n# Set to None to use default OpenCV cascade\n# Or provide custom cascade XML path\n\nFACE_DETECTION_MIN_SIZE = (70, 70)\n# Minimum face size in pixels (width, height)\n\nMAX_FACES_PER_FRAME = 5\n# Maximum number of faces to process per frame\n\n# ============================================\n# Face Recognition Configuration\n# ============================================\nDB_PATH = Path(\"data/db/face_db.npz\")\nMODEL_PATH = \"models/embedder_arcface.onnx\"\n\nRECOGNITION_THRESHOLD = 0.35\n# Distance threshold for face recognition\n# Lower = stricter matching (fewer false positives)\n# Higher = looser matching (fewer false negatives)\n# Recommended: 0.30-0.40\n\nRECOGNITION_THRESHOLD_LOCKED = 0.35 * 1.4\n# Grace multiplier when face is already locked\n# Makes it harder to lose track than to gain lock\n\n# ============================================\n# Face Locking Configuration\n# ============================================\nLOCK_TIMEOUT_SECONDS = 3.0\n# Max time without recognition before lock release\n\nEMA_SMOOTHING_ALPHA = 0.5\n# Exponential Moving Average for bounding box\n# 0.0 = maximum smoothing, 1.0 = no smoothing\n\n# ============================================\n# Action Detection Configuration\n# ============================================\n# Blink Detection\nBLINK_THRESHOLD = 0.20  # Eye Aspect Ratio threshold\nBLINK_MIN_FRAMES = 2    # Minimum consecutive frames for detection\n\n# Smile/Expression Detection\nSMILE_THRESHOLD = 0.45  # Mouth Aspect Ratio threshold\nSMILE_BUFFER_SIZE = 5   # Frames to smooth detection over\n\n# Movement Detection\nMOVEMENT_THRESHOLD_PIXELS = 20  # Pixel distance to trigger movement\n\n# ============================================\n# MQTT Configuration\n# ============================================\nMQTT_BROKER = \"localhost\"\nMQTT_PORT = 1883\nMQTT_CLIENT_ID = \"face-recognition-system-01\"\n\n# Optional authentication\nMQTT_USERNAME = None\nMQTT_PASSWORD = None\n\n# Leave as None if no authentication required\n\n# Topic prefix (for multi-room setup)\nMQTT_TOPIC_PREFIX = \"\"  # e.g., \"room1/\" or \"\"\n\nMQTT_TOPICS = {\n    \"face_actions\": f\"{MQTT_TOPIC_PREFIX}face/actions\",\n    \"face_state\": f\"{MQTT_TOPIC_PREFIX}face/state\",\n    \"servo_command\": f\"{MQTT_TOPIC_PREFIX}servo/command\",\n    \"servo_state\": f\"{MQTT_TOPIC_PREFIX}servo/state\",\n    \"system_status\": f\"{MQTT_TOPIC_PREFIX}system/status\",\n}\n\n# State publish frequency (seconds)\nMQTT_STATE_PUBLISH_INTERVAL = 1.0\n\n# ============================================\n# Servo Configuration\n# ============================================\nSERVO_CENTER_ANGLE = 90\nSERVO_MIN_ANGLE = 0\nSERVO_MAX_ANGLE = 180\n\nSERVO_MOVEMENT_THRESHOLD = 5\n# Minimum angle change to trigger servo update (degrees)\n\nSERVO_SMOOTHING_ENABLED = True\nSERVO_SMOOTHING_ALPHA = 0.3\n# 0.0 = maximum smoothing, 1.0 = no smoothing\n\nSERVO_MIN_PUBLISH_INTERVAL = 100  # milliseconds\n# Rate limiting to prevent servo jitter\n\nSERVO_GESTURE_COOLDOWN = 2.0\n# Minimum time between automatic servo gestures (seconds)\n\n# ============================================\n# Data Logging Configuration\n# ============================================\nHISTORY_DIR = Path(\"data/history\")\n# Directory for action history files\n\nDEBUG_OVERLAY_ENABLED = False\n# Show additional debug information on screen\n\nSAVE_ALIGNED_FACES = False\n# Save aligned face crops for debugging\nALIGNED_FACES_DIR = Path(\"data/debug_aligned\")\n\n# ============================================\n# Performance Configuration\n# ============================================\nDISPLAY_FPS = True\n# Show FPS counter on screen\n\nFPS_CALCULATION_INTERVAL = 30  # frames\n# Update FPS display every N frames\n\n# ============================================\n# Advanced Configuration\n# ============================================\nUSE_GPU = False\n# Enable GPU acceleration (if available)\n# Note: ONNX Runtime with GPU requires CUDA setup\n\nDEBUG_MODE = False\n# Enable verbose logging and debug output\n\nFRAME_SKIP = 0\n# Skip N frames between processing (0 = process every frame)\n# Useful for performance optimization\n\n# ============================================\n# Hardware Configuration\n# ============================================\nESP8266_CONFIG = {\n    \"broker\": MQTT_BROKER,\n    \"port\": MQTT_PORT,\n    \"wifi_ssid\": \"YOUR_SSID\",\n    \"wifi_password\": \"YOUR_PASSWORD\",\n}\n# Flash these credentials to ESP8266 firmware\n\n# ============================================\n# Enrollment Configuration\n# ============================================\nENROLLMENT_CAPTURE_COUNT = 20\n# Number of face images to capture per person\n\nENROLLMENT_FRAME_SKIP = 5\n# Capture every Nth frame to ensure variety\n\n# ============================================\n# Function to load configuration\n# ============================================\ndef load_config():\n    \"\"\"Load and validate configuration.\"\"\"\n    config = {\n        'logging': {\n            'level': LOG_LEVEL,\n            'format': LOG_FORMAT,\n        },\n        'camera': {\n            'index': CAMERA_INDEX,\n            'width': CAMERA_WIDTH,\n            'height': CAMERA_HEIGHT,\n            'fps': CAMERA_FPS,\n        },\n        'detection': {\n            'min_size': FACE_DETECTION_MIN_SIZE,\n            'max_faces': MAX_FACES_PER_FRAME,\n        },\n        'recognition': {\n            'db_path': DB_PATH,\n            'model_path': MODEL_PATH,\n            'threshold': RECOGNITION_THRESHOLD,\n        },\n        'locking': {\n            'timeout': LOCK_TIMEOUT_SECONDS,\n            'smoothing_alpha': EMA_SMOOTHING_ALPHA,\n        },\n        'actions': {\n            'blink': {'threshold': BLINK_THRESHOLD, 'min_frames': BLINK_MIN_FRAMES},\n            'smile': {'threshold': SMILE_THRESHOLD, 'buffer_size': SMILE_BUFFER_SIZE},\n            'movement': {'threshold': MOVEMENT_THRESHOLD_PIXELS},\n        },\n        'mqtt': {\n            'broker': MQTT_BROKER,\n            'port': MQTT_PORT,\n            'client_id': MQTT_CLIENT_ID,\n            'username': MQTT_USERNAME,\n            'password': MQTT_PASSWORD,\n            'topics': MQTT_TOPICS,\n            'state_publish_interval': MQTT_STATE_PUBLISH_INTERVAL,\n        },\n        'servo': {\n            'center': SERVO_CENTER_ANGLE,\n            'min': SERVO_MIN_ANGLE,\n            'max': SERVO_MAX_ANGLE,\n            'movement_threshold': SERVO_MOVEMENT_THRESHOLD,\n            'smoothing': SERVO_SMOOTHING_ENABLED,\n            'smoothing_alpha': SERVO_SMOOTHING_ALPHA,\n            'publish_interval': SERVO_MIN_PUBLISH_INTERVAL,\n            'gesture_cooldown': SERVO_GESTURE_COOLDOWN,\n        },\n        'storage': {\n            'history_dir': HISTORY_DIR,\n            'aligned_dir': ALIGNED_FACES_DIR,\n        },\n    }\n    \n    # Create necessary directories\n    HISTORY_DIR.mkdir(parents=True, exist_ok=True)\n    if SAVE_ALIGNED_FACES:\n        ALIGNED_FACES_DIR.mkdir(parents=True, exist_ok=True)\n    \n    return config\n\n\nif __name__ == \"__main__\":\n    # Test configuration loading\n    config = load_config()\n    import json\n    print(json.dumps({k: str(v) if isinstance(v, Path) else v for k, v in config.items()}, indent=2))\n