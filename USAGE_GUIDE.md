# Usage Guide - Face Recognition & Locked Face Tracking System\n\n## Quick Start\n\n### 1. Database Enrollment\n\nBefore running the system, enroll at least one person's face:\n\n```bash\npython -m src.enroll\n```\n\n**Enrollment Process**:\n1. Enter name: `Oreste` (or your name)\n2. Look at camera from different angles\n3. Press SPACE or ENTER to capture frames\n4. Press 'q' to finish enrollment\n5. Database saved to: `data/db/face_db.npz`\n\n### 2. Start MQTT Broker\n\n**Windows (Mosquitto)**:\n```bash\nmosquitto -v\n```\n\n**Linux**:\n```bash\nsudo systemctl start mosquitto\n```\n\n**macOS**:\n```bash\nbrew services start mosquitto\n```\n\n### 3. Run the Integrated System\n\n```bash\npython -m src.integrated_system\n```\n\n**Expected Output**:\n```\n[INFO] ==================================================\n[INFO] Face Recognition & Locked Face Tracking System\n[INFO] ==================================================\n[INFO] Initializing Face Locking System...\n[INFO] Initializing MQTT Manager...\n[INFO] Initializing Servo Controller...\n[INFO] ✓ Camera initialized: 1280x720\n[INFO] ✓ MQTT broker connected\n```\n\n## System Interface\n\n### Video Display\n\n```\n┌────────────────────────────────────────────────────────┐\n│ Faces: 2 | FPS: 30.2 | Servo: ON                      │\n│ Target: Oreste | Thresh: 0.35                         │\n│ BLINKING                                               │\n│                                                        │\n│  [Green Box - Locked Face]                             │\n│  ├─ [LOCKED] Oreste                                    │\n│  ├─ 5 Keypoints                                        │\n│  │                                                     │\n│  [Gray Box - Other Face]                               │\n│  └─ Unknown                                            │\n│                                                        │\n│                              Servo: 120°               │\n└────────────────────────────────────────────────────────┘\n```\n\n### Status Indicators\n\n- **[LOCKED]** (Green): Face is recognized and locked\n- **[SEARCHING]** (Yellow): Tracking mode, waiting for recognition\n- **BLINKING**: Eye blink detected\n- **SMILING**: Smile/laugh detected\n- **Servo: ON/OFF**: Motor tracking enabled/disabled\n\n## Controls\n\n| Key | Action | Description |\n|-----|--------|-------------|\n| `n` | Next Identity | Switch to next person in database |\n| `p` | Prev Identity | Switch to previous person |\n| `+` | Increase Threshold | Make recognition stricter (less false positives) |\n| `-` | Decrease Threshold | Make recognition looser (more true positives) |\n| `s` | Toggle Servo | Enable/disable servo motor tracking |\n| `c` | Call Gesture | Trigger servo acknowledgment gesture |\n| `q` | Quit | Exit the application |\n\n## Keyboard Controls Examples\n\n### Selecting Target Person\n\n```\nDatabase has: [Angel, Oreste, Prosper]\nCurrent: Oreste (1/3)\n\nPress 'n' → Change to Prosper (2/3)\nPress 'n' → Change to Angel (3/3)\nPress 'n' → Change back to Oreste (1/3)\nPress 'p' → Change to Angel (3/3)\n```\n\n### Adjusting Threshold\n\n```\nThreshold controls how strict face recognition is:\n\nDefault: 0.35\nPress '+' → 0.37 (stricter, fewer false positives)\nPress '+' → 0.39 (even stricter, might miss faces)\nPress '-' → 0.37 (looser, more false positives)\nPress '-' → 0.35 (back to default)\n\nRecommended Range: 0.30 - 0.40\n```\n\n### Servo Control\n\n```\nServo tracks face position automatically when enabled:\n\nPress 's' → Disable servo (motor stops at last position)\nPress 'c' → Make servo acknowledge gesture (sweep left-right)\nPress 's' → Enable servo again (resumes tracking)\n```\n\n## System Workflow\n\n### 1. Face Detection Phase\n\n```\n┌─────────────────────────────────────┐\n│ Camera Input (1280x720 @ 30 FPS)    │\n└──────────────┬──────────────────────┘\n               ↓\n┌─────────────────────────────────────┐\n│ Haar Cascade Detection              │\n│ (Find face regions)                  │\n└──────────────┬──────────────────────┘\n               ↓\n┌─────────────────────────────────────┐\n│ MediaPipe FaceMesh (5-point)        │\n│ (Extract facial landmarks)           │\n└──────────────┬──────────────────────┘\n               ↓\n      Faces Found: 0-5 per frame\n```\n\n### 2. Face Recognition Phase\n\n```\nFor each detected face:\n┌─────────────────────────────────────┐\n│ Align face to 112×112               │\n└──────────────┬──────────────────────┘\n               ↓\n┌─────────────────────────────────────┐\n│ ArcFace ONNX Embedding              │\n│ (Generate 512-d vector)              │\n└──────────────┬──────────────────────┘\n               ↓\n┌─────────────────────────────────────┐\n│ Cosine Distance Matching            │\n│ (Compare to database)                │\n└──────────────┬──────────────────────┘\n               ↓\n     Distance < Threshold? \n     ├─ YES → Known Person (accept)\n     └─ NO → Unknown (reject)\n```\n\n### 3. Face Locking Phase\n\n```\nWhen target person detected:\n\n┌─────────────────────────────────────┐\n│ Lock acquired                       │\n│ • Start history file                │\n│ • Smooth bounding box               │\n│ • Enable action detection           │\n└──────────────┬──────────────────────┘\n               ↓\n        Track face position\n        (even if not recognized)\n        Timeout: 3 seconds\n               ↓\n     Face lost for > 3 seconds?\n     ├─ YES → Release lock\n     └─ NO → Continue tracking\n```\n\n### 4. Action Detection Phase\n\n```\nWhile face is locked:\n\n┌───────────────────────────────────┐\n│ BLINK Detection                   │\n│ • Eye Aspect Ratio (EAR) < 0.20  │\n│ • Duration: 2+ frames            │\n│ • Publishes to: face/actions     │\n└───────────────────────────────────┘\n\n┌───────────────────────────────────┐\n│ SMILE Detection                   │\n│ • Mouth Aspect Ratio (MAR)       │\n│ • Smoothed over 5 frames         │\n│ • Publishes to: face/actions     │\n└───────────────────────────────────┘\n\n┌───────────────────────────────────┐\n│ MOVEMENT Detection                │\n│ • Centroid position change       │\n│ • Threshold: ±20 pixels          │\n│ • Direction: Left/Right          │\n│ • Publishes to: face/actions     │\n└───────────────────────────────────┘\n```\n\n### 5. Servo Tracking Phase\n\n```\nFace position → Servo angle mapping:\n\nFace Position     Servo Angle\nFar Left (0.0)    0°\nLeft (0.25)       45°\nCenter (0.5)      90°\nRight (0.75)      135°\nFar Right (1.0)   180°\n\nSmoothing: EMA with α=0.3\nRate limiting: Min 100ms between commands\nMovement threshold: 5° to trigger update\n```\n\n## MQTT Integration\n\n### Publishing Data\n\nThe system automatically publishes to:\n\n**1. Face Actions**\n```bash\nmosquitto_sub -h localhost -t \"face/actions\"\n\n# Output:\n[10:51:23.230] LOCK_START: System locked onto Oreste\n[10:51:28.628] EXPRESSION: Smile/Laugh detected\n[10:51:33.869] MOVE: Moved Left\n[10:51:42.448] BLINK: Eye blink detected\n```\n\n**2. Face State**\n```bash\nmosquitto_sub -h localhost -t \"face/state\"\n\n# Output (every 1 second when locked):\n{\"timestamp\": \"...\", \"face_name\": \"Oreste\", \"is_locked\": true, \"face_position\": 0.65, \"confidence\": 0.92}\n```\n\n**3. Servo State**\n```bash\nmosquitto_sub -h localhost -t \"servo/state\"\n\n# Output (every 5 seconds from ESP8266):\n{\"current\": 120, \"target\": 120, \"timestamp\": 1234567890}\n```\n\n### Controlling Servo Remotely\n\n```bash\n# Command servo to specific angle\nmosquitto_pub -h localhost -t \"servo/command\" -m \"45\"\n\n# Track left\nmosquitto_pub -h localhost -t \"servo/command\" -m \"20\"\n\n# Center\nmosquitto_pub -h localhost -t \"servo/command\" -m \"90\"\n\n# Track right\nmosquitto_pub -h localhost -t \"servo/command\" -m \"160\"\n```\n\n## Data Logging\n\n### History Files\n\nAction history saved in: `data/history/`\n\n**Format**: `<name>_history_<timestamp>.txt`\n\n**Content**:\n```\n[10:51:23.230] LOCK_START: System locked onto Oreste\n[10:51:28.628] EXPRESSION: Smile/Laugh detected\n[10:51:33.869] MOVE: Moved Left\n[10:51:39.260] MOVE: Moved Left\n[10:51:40.526] MOVE: Moved Left\n[10:51:40.542] EXPRESSION: Smile/Laugh detected\n[10:51:41.109] MOVE: Moved Right\n[10:51:42.448] BLINK: Eye blink detected\n[10:51:57.803] EXPRESSION: Smile/Laugh detected\n```\n\n### Database Files\n\n- `data/db/face_db.npz`: Face embeddings (binary)\n- `data/db/face_db.json`: Metadata (JSON)\n- `data/enroll/<name>/`: Original enrollment images\n\n## Performance Monitoring\n\n### FPS (Frames Per Second)\n\n```\nTarget: 30 FPS\nDisplayed in top-left corner\n\nLow FPS troubleshooting:\n1. Close other applications\n2. Reduce image resolution (Camera settings)\n3. Increase distance threshold (less matching)\n4. Disable servo tracking (less computation)\n```\n\n### Latency Measurements\n\n```python\n# In integrated_system.py\nframetime = 1000 / fps  # milliseconds\n\n30 FPS → ~33ms per frame\n20 FPS → ~50ms per frame\n10 FPS → ~100ms per frame\n```\n\n### System Resources\n\n```\nTypical usage:\n- CPU: 30-40% (1 core at 100%)\n- Memory: 300-500 MB\n- Network: 10-50 kbps (MQTT)\n- Disk: <1 MB/min (logs)\n```\n\n## Advanced Configuration\n\n### Tuning Recognition Threshold\n\n```python\n# In integrated_system.py\nsystem.face_lock_system.matcher.dist_thresh = 0.30  # Stricter\nsystem.face_lock_system.matcher.dist_thresh = 0.40  # Looser\n```\n\n**Recommended values by use case**:\n- Strict (no false positives): 0.25-0.30\n- Balanced (default): 0.33-0.37\n- Loose (fewer misses): 0.40-0.45\n\n### Tuning Servo Behavior\n\n```python\n# In integrated_system.py\nservo = ServoController(\n    mqtt_manager,\n    movement_threshold=5,      # Degrees (lower = more responsive)\n    smoothing_enabled=True,    # EMA smoothing\n    min_publish_interval=100,  # Milliseconds (rate limiting)\n)\n```\n\n### Tuning Action Detection\n\n```python\n# In face_lock.py\nsystem.blink_threshold = 0.20      # EAR threshold\nsystem.smile_threshold = 0.45      # MAR threshold\nsystem.blink_req_frames = 2        # Minimum frames for blink\n```\n\n## Troubleshooting During Operation\n\n### Problem: Face Not Detected\n\n```\nCause: Poor lighting, face too far\nSolution:\n1. Move closer to camera (min 0.5m)\n2. Improve lighting (no backlighting)\n3. Face camera directly\n4. Remove sunglasses/masks\n```\n\n### Problem: Lock Not Acquired\n\n```\nCause: Recognition threshold too strict\nSolution:\n1. Press '-' to decrease threshold\n2. Enroll face with more angles\n3. Move closer to camera\n```\n\n### Problem: Servo Not Moving\n\n```\nCause: MQTT connection issue\nSolution:\n1. Verify MQTT broker running: mosquitto_sub -h localhost -t \"#\"\n2. Check ESP8266 WiFi: Look at serial console\n3. Verify servo power supply\n4. Restart ESP8266\n```\n\n### Problem: Jerky Servo Movement\n\n```\nCause: Too sensitive, updating too frequently\nSolution:\n1. Increase movement_threshold (5 → 10)\n2. Increase min_publish_interval (100 → 200ms)\n3. Enable smoothing: smoothing_enabled=True\n```\n\n## Running Multiple Instances\n\n### For Multi-Room Deployment\n\n```python\n# Room 1\nsystem1 = IntegratedFaceTrackingSystem(\n    camera_index=0,\n    mqtt_client_id=\"face-room1\",\n)\n\n# Room 2\nsystem2 = IntegratedFaceTrackingSystem(\n    camera_index=1,\n    mqtt_client_id=\"face-room2\",\n)\n```\n\n### MQTT Topic Separation\n\n```bash\n# Room 1\nface/room1/actions\nservoe/room1/command\nservo/room1/state\n\n# Room 2\nface/room2/actions\nservo/room2/command\nservo/room2/state\n```\n\n## Safe Shutdown\n\n```\n1. Press 'q' in the application\n2. Wait for cleanup messages\n3. All resources released:\n   ✓ Camera closed\n   ✓ MQTT disconnected\n   ✓ Windows closed\n```\n\n## Next Steps\n\n1. **Set up multiple identities**: Run `src.enroll` for each person\n2. **Deploy servo motor**: Flash ESP8266 with provided firmware\n3. **Mount camera and servo**: Physical installation\n4. **Test MQTT bridge**: Connect multiple systems\n5. **Enable cloud integration**: Forward MQTT to external broker\n6. **Create automation rules**: Process events with external scripts\n\nFor detailed MQTT message specification, see [MQTT_PROTOCOL.md](MQTT_PROTOCOL.md)\n